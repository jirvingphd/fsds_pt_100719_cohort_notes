{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we are using an API to gather articles from a news website and grabbing phrases from two different types of articles:  music and politics.\n",
    "\n",
    "We have a problem though! Only some of our articles have their category (music or politics). Is there a way we can use Machine Learning to help us label our data quickly?\n",
    "\n",
    "-------------------------------\n",
    "### Here are our articles\n",
    "#### Music Articles:\n",
    "\n",
    "* 'the song was popular'\n",
    "* 'band leaders disagreed on sound'\n",
    "* 'played for a sold out arena stadium'\n",
    "\n",
    "#### Politics Articles\n",
    "\n",
    "* 'world leaders met lask week'\n",
    "* 'the election was close'\n",
    "* 'the officials agreed on a compromise'\n",
    "--------------------------------------------------------\n",
    "Let's try and predict one example phrase:\n",
    "\n",
    "\n",
    "* \"world leaders agreed to fund the stadium\"\n",
    "\n",
    "How can we make a model that labels this for us rather than having to go through by hand?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-01T23:32:17.206842Z",
     "start_time": "2020-04-01T23:32:17.117649Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "music = ['the song was popular',\n",
    "         'band leaders disagreed on sound',\n",
    "         'played for a sold out arena stadium']\n",
    "\n",
    "politics = ['world leaders met lask week',\n",
    "            'the election was close',\n",
    "            'the officials agreed on a compromise']\n",
    "\n",
    "test_statement = 'world leaders agreed to fund the stadium'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-01T23:32:17.765822Z",
     "start_time": "2020-04-01T23:32:17.763616Z"
    }
   },
   "outputs": [],
   "source": [
    "#labels : 'music' 'politics'\n",
    "#features: words\n",
    "test_statement_2 = 'officials met at the arena'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"./resources/naive_bayes_icon.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another way of looking at it\n",
    "<img src = \"./resources/another_one.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So, in the context of our problem......"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## $ P(politics | phrase) = \\frac{P(phrase|politics)P(politics)}{P(phrase)}$\n",
    "\n",
    "## $ P(politics) = \\frac{ \\# politics}{\\# all\\ articles} $\n",
    "\n",
    "*where phrase is our test statement*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimating the parameters of our model (using Maximum a Posteriori):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"./resources/solving_theta.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How should we calculate P(politics)?\n",
    "\n",
    "This is essentially the distribution of the probability of either type of article. We have three of each type of article, therefore, we assume that there is an equal probability of either article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-01T23:32:23.329905Z",
     "start_time": "2020-04-01T23:32:23.327349Z"
    }
   },
   "outputs": [],
   "source": [
    "p_politics = len(politics)/(len(politics) + len(music))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-01T23:32:24.049665Z",
     "start_time": "2020-04-01T23:32:24.040775Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_politics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-01T23:32:24.647627Z",
     "start_time": "2020-04-01T23:32:24.644937Z"
    }
   },
   "outputs": [],
   "source": [
    "p_music = len(music)/(len(politics) + len(music))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-01T23:32:25.259945Z",
     "start_time": "2020-04-01T23:32:25.256721Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_music"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do you think we should calculate: $ P(phrase | politics) $ ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-01T23:32:26.362508Z",
     "start_time": "2020-04-01T23:32:26.360517Z"
    }
   },
   "outputs": [],
   "source": [
    "# we need to break the phrases down into individual words\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $ P(phrase | politics) = \\prod_{i=1}^{d} P(word_{i} | politics) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We need to make a *Naive* assumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assuming independence for each word\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $ P(word_{i} | politics) = \\frac{\\#\\ of\\ word_{i}\\ in\\ politics\\ art.} {\\#\\ of\\ total\\ words\\ in\\ politics\\ art.} $\n",
    "\n",
    "### Can you foresee any issues with this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can't have a probability of 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laplace Smoothing\n",
    "## $ P(word_{i} | politics) = \\frac{\\#\\ of\\ word_{i}\\ in\\ politics\\ art. + \\alpha} {\\#\\ of\\ total\\ words\\ in\\ politics\\ art. + \\alpha d} $\n",
    "\n",
    "## $ P(word_{i} | music) = \\frac{\\#\\ of\\ word_{i}\\ in\\ music\\ art. + \\alpha} {\\#\\ of\\ total\\ words\\ in\\ music\\ art. + \\alpha d} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This correction process is called Laplace smoothing:\n",
    "* d : number of features (in this instance total number of vocabulary words)\n",
    "* $\\alpha$ can be any number greater than 0 (it is usually 1)\n",
    "\n",
    "\n",
    "#### Now let's find this calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./resources/IMG_0041.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p(phrase|politics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocab_maker(category):\n",
    "    \"\"\"returns the vocabulary for a given type of article\"\"\"\n",
    "    vocab_category = set()\n",
    "    for art in category:\n",
    "        words = art.split()\n",
    "        for word in words:\n",
    "            vocab_category.add(word)\n",
    "    return vocab_category\n",
    "        \n",
    "voc_music = vocab_maker(music)\n",
    "voc_pol = vocab_maker(politics)\n",
    "total_vocabulary = voc_music.union(voc_pol)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'arena',\n",
       " 'band',\n",
       " 'disagreed',\n",
       " 'for',\n",
       " 'leaders',\n",
       " 'on',\n",
       " 'out',\n",
       " 'played',\n",
       " 'popular',\n",
       " 'sold',\n",
       " 'song',\n",
       " 'sound',\n",
       " 'stadium',\n",
       " 'the',\n",
       " 'was'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc_music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'agreed',\n",
       " 'close',\n",
       " 'compromise',\n",
       " 'election',\n",
       " 'lask',\n",
       " 'leaders',\n",
       " 'met',\n",
       " 'officials',\n",
       " 'on',\n",
       " 'the',\n",
       " 'was',\n",
       " 'week',\n",
       " 'world'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc_pol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_all = voc_music.union(voc_pol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'agreed',\n",
       " 'arena',\n",
       " 'band',\n",
       " 'close',\n",
       " 'compromise',\n",
       " 'disagreed',\n",
       " 'election',\n",
       " 'for',\n",
       " 'lask',\n",
       " 'leaders',\n",
       " 'met',\n",
       " 'officials',\n",
       " 'on',\n",
       " 'out',\n",
       " 'played',\n",
       " 'popular',\n",
       " 'sold',\n",
       " 'song',\n",
       " 'sound',\n",
       " 'stadium',\n",
       " 'the',\n",
       " 'was',\n",
       " 'week',\n",
       " 'world'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_vocab_count = len(voc_all)\n",
    "total_music_count = len(voc_music)\n",
    "total_politics_count = len(voc_pol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#P(politics | leaders agreed to fund the stadium)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_number_words_in_category(phrase,category):\n",
    "    statement = phrase.split()\n",
    "    str_category=' '.join(category)\n",
    "    cat_word_list = str_category.split()\n",
    "    word_count = defaultdict(int)\n",
    "    for word in statement:\n",
    "        for art_word in cat_word_list:\n",
    "            if word == art_word:\n",
    "                word_count[word] +=1\n",
    "            else:\n",
    "                word_count[word]\n",
    "    return word_count\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_music_word_count = find_number_words_in_category(test_statement,music)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'world': 0,\n",
       "             'leaders': 1,\n",
       "             'agreed': 0,\n",
       "             'to': 0,\n",
       "             'fund': 0,\n",
       "             'the': 1,\n",
       "             'stadium': 1})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_music_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_politic_word_count = find_number_words_in_category(test_statement,politics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'world': 1,\n",
       "             'leaders': 1,\n",
       "             'agreed': 1,\n",
       "             'to': 0,\n",
       "             'fund': 0,\n",
       "             'the': 2,\n",
       "             'stadium': 0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_politic_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_likelihood(category_count,test_category_count,alpha):\n",
    "    num = np.product(np.array(list(test_category_count.values())) + alpha)\n",
    "    denom = (category_count + total_vocab_count*alpha)**(len(test_category_count))\n",
    "    \n",
    "    return num/denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "likelihood_m = find_likelihood(total_music_count,test_music_word_count,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood_p = find_likelihood(total_politics_count,test_politic_word_count,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.107740405680756e-11\n",
      "1.748875897714495e-10\n"
     ]
    }
   ],
   "source": [
    "print(likelihood_m)\n",
    "print(likelihood_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $ P(politics | article) = P(politics) x \\prod_{i=1}^{d} P(word_{i} | politics) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deteriming the winner of our model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"./resources/solvingforyhat.png\" width= \"400\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.107740405680756e-11"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likelihood_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# p(politics|article)  > p(music|article)\n",
    "likelihood_p * p_politics  > likelihood_m * p_music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8097960075442886"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likelihood_p /(likelihood_m +likelihood_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19020399245571137"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likelihood_m /(likelihood_m +likelihood_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.053870202840378e-11"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likelihood_m * 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many times, the probabilities we end up are exceedingly small, so we can transform them using logs to save on computation speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $ log(P(politics | article)) = log(P(politics)) + \\sum_{i=1}^{d}log( P(word_{i} | politics)) $\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different Types of Naive Bayes Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multinomial Naive Bayes Classifier: this is the example we just did! It is essentially a collection of a Bernoulli Naive Bayes Classifier. This classifer cannot handle negative values!\n",
    "\n",
    "\n",
    "\n",
    "The Bernoulli Naive Bayes Classifier: used when your features are binary (0 or 1). In the context of a text based classification task, this would be whether or not a word appears in a document at all and calculating the probability of it occuring.\n",
    "\n",
    "<img src = \"./resources/bernoulli_nb_formula.svg\">\n",
    "\n",
    "\n",
    "There is also the Gaussian Naive Bayes Classifier, which assumes that the features that you are predicting based off of are normally distributed.\n",
    "\n",
    "<img src = \"./resources/normal_posterior.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pros:\n",
    "\n",
    "* It is an efficient way to predict class of test data set. It perform well in multi class prediction\n",
    "* When assumption of independence holds, a Naive Bayes classifier performs requires less training data and can perform better than models like logistic regression.\n",
    "* Performs better with categorical inputs. For numerical input, one has to assume a normal distribution.\n",
    "\n",
    "### Cons:\n",
    "\n",
    "* On the other side naive Bayes is also known as a bad estimator, so the probability outputs from predict_proba are not to be taken too seriously.\n",
    "* We are assuming of independent predictors, but in real life, it is almost impossible that we get a set of predictors which are completely independent. (amazingly, still works a lot of the time though!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Naive Bayes in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-cded6637d7bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(X_train,y_train)\n",
    "model.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
