{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mod 3 Project Office Hours / Using SHAP for Explaining Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- online-ds-pt-100719\n",
    "- 04/16/20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Announcements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `cufflinks` and `iplot`\n",
    "- Updating `sklearn` to v 0.22.1\n",
    "    - `sklearn.metrics.plot_confusion_matrix`\n",
    "\n",
    "- Scaling **after** train-test-split\n",
    "- Using `SMOTE` on training data.\n",
    "\n",
    "- Remember Random chance vs your model \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using plotly with pandas via cufflinks\n",
    "```python\n",
    "\n",
    "!pip install -U cufflinks\n",
    "\n",
    "import cufflinks as cf\n",
    "cf.go_offline()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test split and scaling\n",
    "```python\n",
    "X_train,X_test,y_train, y_test= train_test_split(X,y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_sca = scaler.fit_transform(X_train)\n",
    "X_test_sca = scaler.transform(X_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using SMOTE\n",
    "\n",
    "- https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.SMOTE.html\n",
    "\n",
    "\n",
    "- Only oversample your training data, not your test data.\n",
    "\n",
    "- For multiclass - \n",
    "```python\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote= SMOTE(sampling_strategy='all')\n",
    "smote.fit_sample(X_train,y_train)\n",
    "```\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions/Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using SHAP\n",
    "- Jump to other notebook for S.G. demo\n",
    "- See below for copied notes from demo notebook\n",
    "\n",
    "- Documentation:\n",
    " - https://shap.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using SHAP and Shapely Values for Model Interpretation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- White Paper on Shapely Values:\n",
    "    - https://arxiv.org/abs/1705.07874\n",
    "    \n",
    "- Blog Posts:\n",
    "    - https://towardsdatascience.com/explain-your-model-with-the-shap-values-bc36aac4de3d\n",
    "\n",
    "    - https://towardsdatascience.com/explain-any-models-with-the-shap-values-use-the-kernelexplainer-79de9464897a\n",
    "\n",
    "\n",
    "- Videos/Talks:\n",
    "    - [\"Open the Black Box: an intro to Model Interpretability with LIME and SHAP](https://youtu.be/C80SQe16Rao)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Uses game theory to explain feature importance and how a feature steered a model's prediction(s) by removing each feature and seeing the effect on the error.\n",
    "\n",
    "- SHAP has:\n",
    "    - `TreeExplainer`:\n",
    "        - compatible with sckit learn, xgboost, Catboost\n",
    "    - `KernelExplainer`:\n",
    "        - compatible with \"any\" model\n",
    "        \n",
    "\n",
    "\n",
    "- See [this blog post](https://towardsdatascience.com/explain-your-model-with-the-shap-values-bc36aac4de3d) for intro to topic and how to use with trees\n",
    "\n",
    "- For non-tree/random forest models [see this follow up post]( https://towardsdatascience.com/explain-any-models-with-the-shap-values-use-the-kernelexplainer-79de9464897a)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To Get Expanations for Trees:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Import and initialize javascript:\n",
    "\n",
    "```python\n",
    "import shap \n",
    "shap.initjs()\n",
    "```\n",
    "1. Create a shap explainer using your fit model.\n",
    "\n",
    "```python\n",
    "explainer = shap.TreeExplainer(xgb_clf)\n",
    "```\n",
    "\n",
    "2. Get shapely values from explainer for your training data\n",
    "\n",
    "```python\n",
    "shap_values = explainer.shap_values(X_train,y_train)\n",
    "```            \n",
    "\n",
    "3. Select which type of the available plots you'd like to visualize\n",
    "\n",
    "    \n",
    "- **Types of Plots:**\n",
    "    - `summary_plot()`\n",
    "    - `dependence_plot()`\n",
    "    - `force_plot()` for a given observation\n",
    "    - `force_plot()` for all data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "## For normal bar graph of importance:\n",
    "shap.summary_plot(shap_values,X_train,plot_type='bar')\n",
    "\n",
    "## For detail Shapely value visuals:\n",
    "shap.summary_plot(shap_values, X_train)\n",
    "```\n",
    "\n",
    "**`shap.summary_plot`**\n",
    "> - Feature importance: Variables are ranked in descending order.\n",
    "- Impact: The horizontal location shows whether the effect of that value is associated with a higher or lower prediction.\n",
    "- Original value: Color shows whether that variable is high (in red) or low (in blue) for that observation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`shap.dependence_plot`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```python\n",
    "## To Auto-Select Feature Most correlated with a specific feature, just pass the desired feature's column name.\n",
    "\n",
    "shap.dependence_plot('super_dist', shap_values, X_train)\n",
    "\n",
    "## There is a way to specifically call out multiple features but I wasn't able to summarize it quickly for this nb\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`shap.force_plot`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To show an individual data point's prediction and the factors pushing it towards one class or another"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "## Just using np to randomly select a row\n",
    "\n",
    "row = np.random.choice(range(len(X_train))\n",
    "                       \n",
    "shap.force_plot(explainer.expected_value, shap_values[row,:], X_train.iloc[row,:])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
